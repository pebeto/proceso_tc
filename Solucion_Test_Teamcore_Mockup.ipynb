{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c993a96",
   "metadata": {},
   "source": [
    "# Solución al test Teamcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b547e8",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cef63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import pandas as pd\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed50c25",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "Implementar uno o varios procesos que permitan scrapear la información desde la plataforma (https://www.datosabiertos.gob.pe/). Para descargar el reporte en la opción de **Tipos de Contenido** seleccionar **Dataset**, en **Categoría** seleccionar **Economía y Finanzas** y por último en la opción **formato** seleccionar **csv**. El siguiente paso es buscar en el input **Search** el nombre del reporte en este caso **“donaciones”** y dar click en el botón **consultar**. Luego dar **click** en el reporte **“Donaciones COVID-19 - [Ministerio de Economía y Finanzas - MEF]”**. Finalmente debemos descargar el archivo dando click en el botón **descargar** de la opción **Data - Donaciones Covid-19**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea2db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3723273/1858819307.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = webdriver.Firefox(executable_path='./utils/geckodriver')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating into https://www.datosabiertos.gob.pe/\n",
      "Added dataset as Content Type\n",
      "Added economia y finanzas as Category\n",
      "Added csv as Data Format\n",
      "Set donaciones in the search input\n",
      "Clicking on wanted link (defined by end-user)\n",
      "Downloading data and saving into ./data\n",
      "Finishing scraping process\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_OUTPUT_DIRECTORY = './data'\n",
    "\n",
    "class TeamcoreScraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.driver = webdriver.Firefox(executable_path='./utils/geckodriver')\n",
    "\n",
    "    def _get_element_by_xpath(self, xpath_string):\n",
    "        \"\"\"\n",
    "        General abstraction to get elements by xpath. Avoiding method redefinition.\n",
    "        \"\"\"\n",
    "        return self.driver.find_element(By.XPATH, xpath_string)\n",
    "\n",
    "    def _get_elements_by_xpath(self, xpath_string):\n",
    "        \"\"\"\n",
    "        General abstraction to get elements by xpath. Avoiding method redefinition.\n",
    "        \"\"\"\n",
    "        return self.driver.find_elements(By.XPATH, xpath_string)\n",
    "\n",
    "    def _click_last_selectors(self, last_n):\n",
    "        \"\"\"\n",
    "        Click the last selectors, defined from last to first by last_n.\n",
    "        \"\"\"\n",
    "        selectors_elements = self._get_elements_by_xpath(\n",
    "            \"//h2[@class='pane-title ctools-collapsible-handle']\")\n",
    "        for selector_element in selectors_elements[last_n:]:\n",
    "            selector_element.click()\n",
    "\n",
    "    def _get_actual_panel_links(self):\n",
    "        \"\"\"\n",
    "        General abstraction to get actual panel links. Avoiding string redefinition.\n",
    "        \"\"\"\n",
    "        return self._get_elements_by_xpath(\"//a[@class='facetapi-inactive']\")\n",
    "\n",
    "    def _get_url_by_name(self, name):\n",
    "        \"\"\"\n",
    "        Retrieves each panel link. It will change after picking an option, so running this again is necessary.\n",
    "        \"\"\"\n",
    "        panel_links = self._get_actual_panel_links()\n",
    "        for panel_link in panel_links:\n",
    "            link_name = unidecode(panel_link.text.split(\n",
    "                '\\n')[0].split('(')[0].lower().strip()) # Removing unnecesary text and lowercasing\n",
    "            if link_name == name:\n",
    "                url = panel_link.get_attribute('href')\n",
    "                return url\n",
    "\n",
    "    def _select_option(self, name, click_last_selectors=0):\n",
    "        \"\"\"\n",
    "        General abstraction for option picking.\n",
    "        \"\"\"\n",
    "        if click_last_selectors:\n",
    "            self._click_last_selectors(click_last_selectors) # To enable the last hidden panel entries\n",
    "        return self._get_url_by_name(name)\n",
    "\n",
    "    def _set_selection_criteria(self, content_type, category, data_format):\n",
    "        \"\"\"\n",
    "        Set the three steps in the selection criteria.\n",
    "        \"\"\"\n",
    "        content_type_url = self._select_option(content_type)\n",
    "        self.driver.get(content_type_url)\n",
    "        print(f'Added {content_type} as Content Type')\n",
    "\n",
    "        category_url = self._select_option(category)\n",
    "        self.driver.get(category_url)\n",
    "        print(f'Added {category} as Category')\n",
    "\n",
    "        data_format_url = self._select_option(\n",
    "            data_format, click_last_selectors=1) # In this case we just need one hidden panel entry\n",
    "        self.driver.get(data_format_url)\n",
    "        print(f'Added {data_format} as Data Format')\n",
    "\n",
    "    def _set_search_term(self, report_name):\n",
    "        \"\"\"\n",
    "        Write the report_name into the search input.\n",
    "        \"\"\"\n",
    "        search_input_element = self._get_element_by_xpath(\n",
    "            \"//input[@class='form-control form-text']\")\n",
    "        search_input_element.send_keys(report_name)\n",
    "        print(f'Set {report_name} in the search input')\n",
    "        search_input_element.submit()\n",
    "\n",
    "    def _execute_custom_behavior(self):\n",
    "        \"\"\"\n",
    "        Click on the single link and downloading the file related to it.\n",
    "        \"\"\"\n",
    "        self.driver.implicitly_wait(1) # Webpage loads slower, so our scraper needs to wait.\n",
    "        wanted_link_element = self._get_element_by_xpath(\n",
    "            \"//a[@title='Donaciones COVID-19 - [Ministerio de Economía y Finanzas - MEF]']\")\n",
    "        wanted_link_element.click()\n",
    "        print(f'Clicking on wanted link (defined by end-user)')\n",
    "\n",
    "        download_button_element = self._get_element_by_xpath(\n",
    "            \"//a[@title='Data - Donaciones Covid-19']/following-sibling::span/a\")\n",
    "        download_button_link = download_button_element.get_attribute('href')\n",
    "        res = requests.get(download_button_link)\n",
    "        print(f'Downloading data and saving into {DOWNLOAD_OUTPUT_DIRECTORY}')\n",
    "        open(f'{DOWNLOAD_OUTPUT_DIRECTORY}/data.zip', 'wb').write(res.content) # We save the file with this method to use the project internal folder structure\n",
    "\n",
    "    def scrap_data(self, content_type, category, data_format, report_name):\n",
    "        \"\"\"\n",
    "        Extracts data from the url defined in the class.\n",
    "\n",
    "        This method is divided in three processes:\n",
    "        - Set the selection criteria by using the content type, the category and data format\n",
    "        - Set the search term by the report name\n",
    "        - Execute custom behavior (defined by the end-user)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        content_type : str\n",
    "            A string representating the content type\n",
    "        category : str\n",
    "            A string representating the category\n",
    "        data_format : str\n",
    "            A string representating the data format\n",
    "        report_name : str\n",
    "            A string representating the report name\n",
    "        \"\"\"\n",
    "        print(f'Navigating into {self.url}')\n",
    "        self.driver.get(self.url)\n",
    "        self._set_selection_criteria(content_type, category, data_format)\n",
    "        self._set_search_term(report_name)\n",
    "        self._execute_custom_behavior()\n",
    "        print(f'Finishing scraping process')\n",
    "\n",
    "scraper = TeamcoreScraper('https://www.datosabiertos.gob.pe/')\n",
    "scraper.scrap_data('dataset', 'economia y finanzas', 'csv', 'donaciones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce03424",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "Crear un proceso que tenga como entrada el nombre del archivo y leerlo con el paquete de pandas pandas. Luego se debe filtrar por la columna REGIÓN, y guardar un archivo con la información de cada región, el nombre del archivo csv debe ser el de la región en minúsculas. Por ejemplo “lima.csv” y la información que contiene debe pertenecer solo de la región Lima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b383582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A csv file for LIMA was generated in ./region_data...\n",
      "A csv file for LORETO was generated in ./region_data...\n",
      "A csv file for CAJAMARCA was generated in ./region_data...\n",
      "A csv file for MADRE DE DIOS was generated in ./region_data...\n",
      "A csv file for HUANUCO was generated in ./region_data...\n",
      "A csv file for AMAZONAS was generated in ./region_data...\n",
      "A csv file for UCAYALI was generated in ./region_data...\n",
      "A csv file for AREQUIPA was generated in ./region_data...\n",
      "A csv file for HUANCAVELICA was generated in ./region_data...\n",
      "A csv file for CUSCO was generated in ./region_data...\n",
      "A csv file for TACNA was generated in ./region_data...\n",
      "A csv file for LA LIBERTAD was generated in ./region_data...\n",
      "A csv file for JUNIN was generated in ./region_data...\n",
      "A csv file for APURIMAC was generated in ./region_data...\n",
      "A csv file for AYACUCHO was generated in ./region_data...\n",
      "A csv file for PROVINCIA CONSTITUCIONAL DEL CALLAO was generated in ./region_data...\n",
      "A csv file for TUMBES was generated in ./region_data...\n",
      "A csv file for PUNO was generated in ./region_data...\n",
      "A csv file for ANCASH was generated in ./region_data...\n",
      "A csv file for SAN MARTIN was generated in ./region_data...\n",
      "A csv file for MOQUEGUA was generated in ./region_data...\n",
      "A csv file for PIURA was generated in ./region_data...\n",
      "A csv file for ICA was generated in ./region_data...\n",
      "A csv file for LAMBAYEQUE was generated in ./region_data...\n",
      "A csv file for PASCO was generated in ./region_data...\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIRECTORY = './region_data'\n",
    "\n",
    "def create_region_data_by_initial_csv(path_to_file):\n",
    "    \"\"\"\n",
    "    Creates new .csv files for each region by an initial csv file. It accepts compressed files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_file : str\n",
    "        Path to the initial csv file to be readed\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path_to_file, encoding='latin-1')\n",
    "    regions = df['REGION'].unique()\n",
    "    for region in regions:\n",
    "        region_df = df[df['REGION'] == region]\n",
    "        region_df.to_csv(f'{OUTPUT_DIRECTORY}/{region.lower()}.csv', index=False)\n",
    "        print(f'A csv file for {region} was generated in {OUTPUT_DIRECTORY}...')\n",
    "create_region_data_by_initial_csv('./data/data.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
